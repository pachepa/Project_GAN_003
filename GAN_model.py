import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras import Sequential, Input
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy
from utils import Backtesting, calculate_passive_benchmark

class GANModel:
    def __init__(self, input_dim, sequence_length):
        self.input_dim = input_dim
        self.sequence_length = sequence_length
        self.loss_fn = BinaryCrossentropy()
        self.optimizer_gen = Adam(learning_rate=0.0002, beta_1=0.5)
        self.optimizer_disc = Adam(learning_rate=0.0002, beta_1=0.5)
        self.generator = self.build_generator()
        self.discriminator = self.build_discriminator()

    def build_generator(self):
        model = Sequential([
            Input(shape=(self.input_dim,)),
            Dense(128, activation="relu"),
            Dense(256, activation="relu"),
            Dense(self.sequence_length, activation="linear")
        ])
        return model

    def build_discriminator(self):
        model = Sequential([
            Input(shape=(self.sequence_length,)),
            Dense(256, activation="relu"),
            Dense(128, activation="relu"),
            Dense(1, activation="sigmoid")
        ])
        #model.compile(loss=self.loss_fn, optimizer=self.optimizer_disc)
        return model

    def train(self, normalized_prices, epochs=100, batch_size=32):  # Reduce epochs for testing
        yearly_prices = normalized_prices[:((len(normalized_prices) // 252) -1)*252].reshape(-1, 252)
        batch_size = len(yearly_prices)
        for epoch in range(epochs):
            noise = np.random.normal(0, 1, (batch_size, self.input_dim))
            with tf.GradientTape() as tape_gen, tf.GradientTape() as tape_disc:
                generated_data = self.generator(noise, training=True)
                real_output = self.discriminator(yearly_prices, training=True)
                fake_output = self.discriminator(generated_data, training=True)
                d_loss = -(tf.math.reduce_mean(real_output) - tf.math.reduce_mean(fake_output))
                g_loss = -tf.math.reduce_mean(fake_output)

            grads_disc = tape_disc.gradient(d_loss, self.discriminator.trainable_variables)
            self.optimizer_disc.apply_gradients(zip(grads_disc, self.discriminator.trainable_variables))

            grads_gen = tape_gen.gradient(g_loss, self.generator.trainable_variables)
            self.optimizer_gen.apply_gradients(zip(grads_gen, self.generator.trainable_variables))

            # Print progress every 10 epochs for more frequent feedback
            if epoch % 10 == 0:
                print(f"Epoch {epoch}/{epochs} - [D loss: {d_loss.numpy()}] [G loss: {g_loss.numpy()}]")

    def generate_synthetic_data(self, n_scenarios=100):  # Reduce scenarios for faster testing
        synthetic_data = []
        for i in range(n_scenarios):
            noise = np.random.normal(0, 1, (1, self.input_dim))
            generated_sequence = self.generator.predict(noise)
            synthetic_data.append(generated_sequence.flatten())
            print(f"Generated synthetic scenario {i + 1}/{n_scenarios}")  # Progress tracking

        synthetic_df = pd.DataFrame(synthetic_data).transpose()
        synthetic_df.columns = [f'Scenario_{i+1}' for i in range(n_scenarios)]
        synthetic_df.to_csv('synthetic_data_AMZN.csv', index=False)
        return synthetic_df


def main():
    data_path = 'cleaned_data_AMZN.csv'
    print("Loading data...")
    data = pd.read_csv(data_path)
    prices = data['Close'].values
    normalized_prices = (prices - np.mean(prices)) / np.std(prices)

    # Initialize and train the GAN model
    print("Initializing GAN model...")
    gan_model = GANModel(input_dim=300, sequence_length=252)

    print("Starting GAN training...")
    gan_model.train(normalized_prices)
    print("GAN training completed.")

    print("Generating synthetic data...")
    synthetic_df = gan_model.generate_synthetic_data(n_scenarios=100)
    print("Synthetic data generation completed.")

    print("Plotting synthetic data...")
    plt.figure(figsize=(12, 6))
    for i in range(5):
        plt.plot(synthetic_df.index, synthetic_df[f'Scenario_{i + 1}'], label=f'Scenario {i + 1}')
    plt.title("Sample Synthetic Stock Price Paths Generated by GAN")
    plt.xlabel("Time Steps")
    plt.ylabel("Normalized Price")
    plt.legend()
    plt.show()
    plt.close()
    print("Synthetic data plotting completed.")

    print("Initializing backtester...")
    backtester = Backtesting('cleaned_data_AMZN.csv', 'synthetic_data_AMZN.csv')

    print("Running backtest on historical data with SL/TP variations...")
    final_cash_active_strategy = backtester.run_all_sl_tp_variations()
    print("Historical backtest with SL/TP variations completed.")

    print("Running backtest on synthetic data scenarios...")
    backtester.backtest_synthetic_scenarios(num_scenarios=100)  # Adjust the number of scenarios as needed
    print("Synthetic scenarios backtest completed.")

    print("\nCalculating annual performance metrics for active strategy...")
    strategy_metrics = backtester.calculate_annual_performance(
        initial_cash=1_000_000,
        final_cash=final_cash_active_strategy,
        data=backtester.historical_data
    )
    print("Active Strategy Annual Performance Metrics:")
    for metric, value in strategy_metrics.items():
        print(f"  {metric}: {value:.4f}")

    print("\nRunning benchmark passive strategy...")
    benchmark_metrics = calculate_passive_benchmark(data, strategy_final_cash=final_cash_active_strategy)
    print("Benchmark Passive Strategy Results:")
    for metric, value in benchmark_metrics.items():
        print(f"  {metric}: {value:.4f}")


if __name__ == "__main__":
    main()
